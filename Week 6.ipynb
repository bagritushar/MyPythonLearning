{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14116b85-8d89-47a7-881a-6e89a18fa589",
   "metadata": {},
   "source": [
    "<font color=\"Blue\" size=\"6\">Python Learning 6th Week</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b59f5-91c4-471a-891d-3fe7fa793a39",
   "metadata": {},
   "source": [
    "# Week 6 â€“ Machine Learning Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b5854-c2e6-401d-9bcf-4ca11770fe19",
   "metadata": {},
   "source": [
    " # 1. Data Preprocessing (Missing Values, Label Encoding)\n",
    "# Data Preprocessing in Machine Learning\n",
    "\n",
    "Machine Learning model banane se pehle hamesha data ko clean aur transform karna padta hai.\n",
    "Do basic steps jo ham use karte hain:\n",
    "\n",
    "Missing Values handle karna (mean/median/mode/forward fill, etc.)\n",
    "\n",
    "Label Encoding (categorical data ko numeric me convert karna)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08acbcb-f99c-478b-aad6-fe297f84b37e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff01b636-4b6d-40b8-ae26-9ea221497e43",
   "metadata": {},
   "source": [
    " # Missing Values Handling\n",
    "\n",
    "ðŸ”¹ Why?\n",
    "Machine Learning models NaN (missing values) samajh nahi paate, isliye hame unhe fill / remove karna padta hai.\n",
    "\n",
    "Example Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6acf8b38-0f8f-4bca-ae7d-7b68113a8ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     Name   Age  Marks  Gender\n",
      "0   Amit  25.0   85.0    Male\n",
      "1   Ravi   NaN   90.0    Male\n",
      "2   Neha  28.0    NaN  Female\n",
      "3  Priya   NaN   75.0  Female\n",
      "4  Karan  22.0    NaN    None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Dummy data\n",
    "data = {\n",
    "    \"Name\": [\"Amit\", \"Ravi\", \"Neha\", \"Priya\", \"Karan\"],\n",
    "    \"Age\": [25, None, 28, None, 22],\n",
    "    \"Marks\": [85, 90, None, 75, None],\n",
    "    \"Gender\": [\"Male\", \"Male\", \"Female\", \"Female\", None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331dc3d1-f06a-486a-b13b-063e17807cb5",
   "metadata": {},
   "source": [
    "# Solution 1: Numerical Columns â†’ Fill with Mean / Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb06191-8934-4f88-a480-341cdf996148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age column -> mean\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "\n",
    "# Marks column -> median\n",
    "df[\"Marks\"] = df[\"Marks\"].fillna(df[\"Marks\"].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8d2f6-0cf9-4189-bd6c-2d2f0066fed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdf894a1-741b-42e0-a211-db9dbb6655a4",
   "metadata": {},
   "source": [
    "# Solution 2: Categorical Columns â†’ Fill with Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f736a82-3eff-4e1a-b2eb-aea24f932319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender column -> mode\n",
    "df[\"Gender\"] = df[\"Gender\"].fillna(df[\"Gender\"].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c098dea-7250-4a3b-9a61-bf2608dd3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated DataFrame:\n",
    "\n",
    "    Name   Age  Marks  Gender\n",
    "0   Amit  25.0   85.0    Male\n",
    "1   Ravi  25.0   90.0    Male\n",
    "2   Neha  28.0   85.0  Female\n",
    "3  Priya  25.0   75.0  Female\n",
    "4  Karan  22.0   85.0    Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c8abe8-95b4-4ed6-a1c7-9658dcedad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     Name   Age  Marks  Gender\n",
      "0   Amit  25.0   85.0    Male\n",
      "1   Ravi   NaN   90.0    Male\n",
      "2   Neha  28.0    NaN  Female\n",
      "3  Priya   NaN   75.0  Female\n",
      "4  Karan  22.0    NaN    None\n",
      "\n",
      "Cleaned DataFrame:\n",
      "     Name   Age  Marks  Gender\n",
      "0   Amit  25.0   85.0    Male\n",
      "1   Ravi  25.0   90.0    Male\n",
      "2   Neha  28.0   85.0  Female\n",
      "3  Priya  25.0   75.0  Female\n",
      "4  Karan  22.0   85.0  Female\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Name\": [\"Amit\", \"Ravi\", \"Neha\", \"Priya\", \"Karan\"],\n",
    "    \"Age\": [25, None, 28, None, 22],\n",
    "    \"Marks\": [85, 90, None, 75, None],\n",
    "    \"Gender\": [\"Male\", \"Male\", \"Female\", \"Female\", None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# ðŸ”¹ Numerical fill\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())       # mean\n",
    "df[\"Marks\"] = df[\"Marks\"].fillna(df[\"Marks\"].median())  # median\n",
    "\n",
    "# ðŸ”¹ Categorical fill\n",
    "df[\"Gender\"] = df[\"Gender\"].fillna(df[\"Gender\"].mode()[0])\n",
    "\n",
    "print(\"\\nCleaned DataFrame:\\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da578662-8e3b-4fa4-9b65-4371f0a1a506",
   "metadata": {},
   "source": [
    " # Label Encoding (Categorical â†’ Numeric)\n",
    "\n",
    "Machine Learning algorithms numbers ke sath kaam karte hain, strings ke sath nahi.\n",
    "\n",
    "Example: Gender Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2734b7c1-626d-42c4-ac66-2e25e9f52376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"Gender\"] = le.fit_transform(df[\"Gender\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e2a194d-f1af-4ff2-9167-162cf7dca1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name   Age  Marks  Gender\n",
      "0   Amit  25.0   85.0       1\n",
      "1   Ravi  25.0   90.0       1\n",
      "2   Neha  28.0   85.0       0\n",
      "3  Priya  25.0   75.0       0\n",
      "4  Karan  22.0   85.0       0\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"Gender\"] = le.fit_transform(df[\"Gender\"])\n",
    "\n",
    "print(df.head())        # DataFrame ka 1st 5 rows print hoga\n",
    "print(df[\"Gender\"].unique())   # Gender column ka encoded unique values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c9fe50-f43e-4d1a-8104-2f874b7f7c9f",
   "metadata": {},
   "source": [
    "# Train / Test Split\n",
    "Kya hai?\n",
    "\n",
    "Machine Learning model banate time hum apne dataset ko 2 parts me divide karte hain:\n",
    "\n",
    "Training set â†’ Model ko train karne ke liye (patterns learn karne ke liye).\n",
    "\n",
    "Testing set â†’ Model ko test karne ke liye (check karne ke liye ki model sahi seekh raha hai ya nahi).\n",
    "\n",
    " Agar pura data training me de doge, model sab kuch rat lega (overfitting) aur naye data pe fail hoga.\n",
    "Isliye unseen data (test set) pe evaluate karna zaroori hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a752547-7ca6-451e-b727-b7b76a3e7fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cad8bb-55a9-44f1-8134-65f8222c1d63",
   "metadata": {},
   "source": [
    "# Cross-Validation (CV)\n",
    "Kya hai?\n",
    "\n",
    "Jab dataset chhota ho ya ek single train-test split reliable na ho, tab hum Cross-Validation use karte hain.\n",
    "\n",
    "Process:\n",
    "\n",
    "Dataset ko k equal parts (folds) me divide karo.\n",
    "\n",
    "Har baar ek part ko test ke liye use karo, baaki (k-1) parts ko train ke liye.\n",
    "\n",
    "Ye process k baar repeat hota hai.\n",
    "\n",
    "Final accuracy = sab runs ka average.\n",
    "\n",
    "Isko bolte hain k-Fold Cross Validation.\n",
    "\n",
    "Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce9553f8-bba8-4da6-9835-f06f893f676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.96666667 0.96666667 0.9        0.96666667 1.        ]\n",
      "Average Accuracy: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# 5-fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Average Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b571553-367d-4591-b85c-47f808db799f",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Train/Test Split â†’ Simple, fast evaluation (ek hi exam jaisa).\n",
    "\n",
    "Cross-Validation â†’ Reliable evaluation (multiple exams ka average jaisa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bac061-06a4-477c-ad29-3ec572593900",
   "metadata": {},
   "source": [
    "# Accuracy, Confusion Matrix, Precision / Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90689eab-d875-4b40-955c-46b86c080719",
   "metadata": {},
   "source": [
    "# 1. Accuracy\n",
    "\n",
    "Definition:\n",
    "Accuracy = (Correct Predictions) Ã· (Total Predictions)\n",
    "\n",
    " Matlab model ne kitne answers sahi diye total answers me se.\n",
    "\n",
    "# Formula:\n",
    "Accuracy= TP+TN/TP+TN+FP+FN\n",
    "\t\n",
    "\n",
    "\n",
    "TP (True Positive) = Positive ko correctly Positive predict karna\n",
    "\n",
    "TN (True Negative) = Negative ko correctly Negative predict karna\n",
    "\n",
    "FP (False Positive) = Negative ko galat se Positive predict karna\n",
    "\n",
    "FN (False Negative) = Positive ko galat se Negative predict karna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164afd9-994b-4c58-baaf-a5cb1959f055",
   "metadata": {},
   "source": [
    "# Example:\n",
    "\n",
    "100 patients â†’ model ne 90 sahi predict kiye (70 healthy + 20 sick) â†’\n",
    "Accuracy = 90/100 = 90%\n",
    "\n",
    " Problem: Agar data imbalance ho (e.g., 95% healthy, 5% sick), to model sabko healthy bolega fir bhi accuracy high dikhayega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dadbb89-ccbf-4805-aaf7-ea5c341a05b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2 1]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0]   # Actual\n",
    "y_pred = [1, 0, 1, 0, 0, 1, 1]   # Predicted\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0af9365-168e-420f-971b-bded8feaf42c",
   "metadata": {},
   "source": [
    "# Matlab:\n",
    "\n",
    "TN = 2\n",
    "\n",
    "FP = 1\n",
    "\n",
    "FN = 1\n",
    "\n",
    "TP = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78d8d7a-22ee-4519-8e7c-55e4dad68da9",
   "metadata": {},
   "source": [
    "# 3. Precision\n",
    "\n",
    "Definition:\n",
    "Precision batata hai ki jo model ne positive bola, usme se kitne actually positive the.\n",
    "\n",
    "# Formula:\n",
    "\n",
    "Precision=TP+TP/FP\n",
    "\n",
    "\n",
    " â€œHow many of the predicted positives are actually correct?â€\n",
    "\n",
    "# Example:\n",
    "\n",
    "Model ne 30 patients ko sick bola â†’ 25 sach me sick the, 5 galat the.\n",
    "Precision = 25 / (25+5) = 83.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f0c76-546a-4cf4-a085-25611bc25daf",
   "metadata": {},
   "source": [
    "# 4. Recall (Sensitivity / True Positive Rate)\n",
    "\n",
    "Definition:\n",
    "Recall batata hai ki actual positive cases me se model kitne detect kar paya.\n",
    "\n",
    "Formula:\n",
    "Recall= TP+TP/FN\n",
    "\n",
    " â€œOut of all actual positives, how many did the model correctly identify?â€\n",
    "\n",
    "Example:\n",
    "\n",
    "Total 40 sick patients the â†’ Model ne 25 ko correctly sick bola aur 15 miss kar diye.\n",
    "Recall = 25 / (25+15) = 62.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea47cd30-199c-4ad1-8ff3-ae12f4ade7b3",
   "metadata": {},
   "source": [
    "# Code Example (All Together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95064b92-facc-44e3-a52a-18a71547615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7142857142857143\n",
      "Confusion Matrix:\n",
      " [[2 1]\n",
      " [1 3]]\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0]\n",
    "y_pred = [1, 0, 1, 0, 0, 1, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c494cef-1811-40d7-a059-c445335399e1",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Accuracy â†’ overall correctness\n",
    "\n",
    "Confusion Matrix â†’ detailed view of errors (TP, TN, FP, FN)\n",
    "\n",
    "Precision â†’ quality of positive predictions\n",
    "\n",
    "Recall â†’ ability to catch all positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19511c-b675-47cb-98e4-a0a6e99f8fec",
   "metadata": {},
   "source": [
    "# Save Model (Pickle)\n",
    "Kya hai?\n",
    "\n",
    "Jab hum machine learning model train kar lete hain to har baar dobara training karna time-consuming hota hai.\n",
    "Isliye hum model ko file ke form me save kar lete hain â†’ baad me directly load karke use kar sakte ho.\n",
    "\n",
    "Python me model save/load karne ke liye mainly 2 libraries use hoti hain:\n",
    "\n",
    "Pickle (general Python objects ke liye)\n",
    "\n",
    "Joblib (large numpy arrays ke liye optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00ffc6-e53b-4a62-bbbb-9c3706f831c5",
   "metadata": {},
   "source": [
    "# Example with Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e967c636-2f1e-49f2-92dd-e18788df470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Predictions: [0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train model\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# ---- Save model ----\n",
    "with open(\"model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# ---- Load model ----\n",
    "with open(\"model.pkl\", \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Test loaded model\n",
    "print(\"Predictions:\", loaded_model.predict([[5.1, 3.5, 1.4, 0.2]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f43ce42-7cac-4f37-ad6c-de7c8a185afe",
   "metadata": {},
   "source": [
    "# Example with Joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d78dd-9d73-491f-8a6e-cc8754e91fbf",
   "metadata": {},
   "source": [
    "import joblib\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train model\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# ---- Save ----\n",
    "joblib.dump(model, \"model_joblib.pkl\")\n",
    "\n",
    "# ---- Load ----\n",
    "loaded_model = joblib.load(\"model_joblib.pkl\")\n",
    "print(\"Predictions:\", loaded_model.predict([[6.2, 3.4, 5.4, 2.3]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f2d0f-72a8-4680-9876-f55822e9b3a0",
   "metadata": {},
   "source": [
    "# Where is it useful?\n",
    "\n",
    "Jab tum model ko deploy karna chahte ho (Flask/Django/Streamlit app me).\n",
    "\n",
    "Future me dobara train ki zaroorat na ho.\n",
    "\n",
    "Large datasets ke sath time save karne ke liye.\n",
    "\n",
    "# Summary of Week 6 Topics\n",
    "\n",
    "Data Processing (Missing values, Label Encoding)\n",
    "\n",
    "Train/Test Split & Cross-Validation\n",
    "\n",
    "Accuracy, Confusion Matrix, Precision, Recall\n",
    "\n",
    "Save Model (Pickle/Joblib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d673f-6d05-4e8a-afd0-9f00989da6f2",
   "metadata": {},
   "source": [
    "# Project 1 - : Flight Delay predictor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c87f0e-9aee-4bb7-8922-d97263e00341",
   "metadata": {},
   "source": [
    "# Project 1 â€“ Flight Delay Predictor\n",
    "# Step 1: Problem Statement\n",
    "\n",
    "Goal = Predict karna ki flight delay hogi ya nahi based on given flight data.\n",
    "\n",
    "Input: flight details (airline, departure time, distance, etc.)\n",
    "\n",
    "Output: Delayed (1) ya Not Delayed (0)\n",
    "\n",
    "# Step 2: Dataset\n",
    "\n",
    "Flight Delay dataset ka use karenge. Example dataset available hai Kaggle pe:\n",
    " \"Airline Delay Dataset\" (features: airline, origin, destination, distance, dep_time, arr_time, delay).\n",
    "\n",
    "# Step 3: Project Pipeline\n",
    "\n",
    "- Load Dataset\n",
    "\n",
    "Pandas se CSV read karna\n",
    "\n",
    "- Data Preprocessing\n",
    "\n",
    "Missing values handle karna\n",
    "\n",
    "Categorical encoding (Airline, Airport names â†’ Label Encoding / OneHotEncoding)\n",
    "\n",
    "- Split Data\n",
    "\n",
    "Train / Test Split (80/20)\n",
    "\n",
    "- Model Training\n",
    "\n",
    "Use RandomForestClassifier (ya DecisionTree for simplicity)\n",
    "\n",
    "- Evaluation\n",
    "\n",
    "Accuracy\n",
    "\n",
    "Confusion Matrix\n",
    "\n",
    "Precision & Recall\n",
    "\n",
    "- Save Model\n",
    "\n",
    "Pickle / Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05ee0700-1285-46af-818c-c30a12e8f035",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'flights.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 1. Load Dataset\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflights.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 2. Data Preprocessing\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Fill missing values\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'flights.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "import pickle\n",
    "\n",
    "# 1. Load Dataset\n",
    "df = pd.read_csv(\"flights.csv\")\n",
    "print(df.head())\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "# Fill missing values\n",
    "df = df.fillna(method=\"ffill\")\n",
    "\n",
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "df[\"Airline\"] = le.fit_transform(df[\"Airline\"])\n",
    "df[\"Origin\"] = le.fit_transform(df[\"Origin\"])\n",
    "df[\"Destination\"] = le.fit_transform(df[\"Destination\"])\n",
    "\n",
    "# Features and Target\n",
    "X = df[[\"Airline\", \"Origin\", \"Destination\", \"Distance\", \"DepTime\"]]\n",
    "y = df[\"Delayed\"]   # 1 = Delayed, 0 = On-time\n",
    "\n",
    "# 3. Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Train Model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "\n",
    "# 6. Save Model\n",
    "with open(\"flight_delay_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model Saved Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5973b42-1f0c-495b-8ced-5df9f5d140bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Tushar/Downloads/airline_delay.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/Tushar/Downloads/airline_delay.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Tushar/Downloads/airline_delay.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/Tushar/Downloads/airline_delay.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5e1c1b1-6d49-4d2b-ad6c-c60d33007faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe2645-8e45-44c2-85c0-a32f562ae3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
